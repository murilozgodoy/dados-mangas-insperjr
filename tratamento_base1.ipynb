{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03113f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de NaNs após tratamento: 0\n",
      "                                                   missing_original  \\\n",
      "indice_valor_agregado_1a5                                      98.0   \n",
      "produto                                                        94.0   \n",
      "empresa                                                        91.0   \n",
      "indice_capex_1a5                                               91.0   \n",
      "tipo_cliente                                                   90.0   \n",
      "indice_escalabilidade_1a5                                      90.0   \n",
      "indice_compatibilidade_refugo_1a5                              87.0   \n",
      "indice_concorrencia_1a5                                        84.0   \n",
      "mercado_principal                                              80.0   \n",
      "margem_media_percentual                                        79.0   \n",
      "certificacoes_principais                                       79.0   \n",
      "indice_complexidade_produtiva_1a5                              78.0   \n",
      "faturamento_empresa_brl                                        76.0   \n",
      "indice_exigencia_regulatoria_1a5                               69.0   \n",
      "indice_compatibilidade_operacao_fazenda_1a5                    67.0   \n",
      "miss__certificacoes_principais                                  NaN   \n",
      "miss__empresa                                                   NaN   \n",
      "miss__faturamento_empresa_brl                                   NaN   \n",
      "miss__indice_capex_1a5                                          NaN   \n",
      "miss__indice_compatibilidade_operacao_fazenda_1a5               NaN   \n",
      "\n",
      "                                                   missing_final  \n",
      "indice_valor_agregado_1a5                                      0  \n",
      "produto                                                        0  \n",
      "empresa                                                        0  \n",
      "indice_capex_1a5                                               0  \n",
      "tipo_cliente                                                   0  \n",
      "indice_escalabilidade_1a5                                      0  \n",
      "indice_compatibilidade_refugo_1a5                              0  \n",
      "indice_concorrencia_1a5                                        0  \n",
      "mercado_principal                                              0  \n",
      "margem_media_percentual                                        0  \n",
      "certificacoes_principais                                       0  \n",
      "indice_complexidade_produtiva_1a5                              0  \n",
      "faturamento_empresa_brl                                        0  \n",
      "indice_exigencia_regulatoria_1a5                               0  \n",
      "indice_compatibilidade_operacao_fazenda_1a5                    0  \n",
      "miss__certificacoes_principais                                 0  \n",
      "miss__empresa                                                  0  \n",
      "miss__faturamento_empresa_brl                                  0  \n",
      "miss__indice_capex_1a5                                         0  \n",
      "miss__indice_compatibilidade_operacao_fazenda_1a5              0  \n",
      "Arquivo salvo: BASE_1_Manga_Produtos_TRATADA.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer \n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "\n",
    "df_raw = pd.read_csv(\"BASE_1_Manga_Produtos.csv\")\n",
    "df = df_raw.copy()\n",
    "\n",
    "missing_mask = df.isna()\n",
    "\n",
    "# Indicadores de missing (boa prática p/ MAR/MNAR)\n",
    "\n",
    "for c in df.columns:\n",
    "    if df[c].isna().any():\n",
    "        df[f\"miss__{c}\"] = df[c].isna().astype(int)\n",
    "\n",
    "# 3) Tratamento por regra (empresa -> faturamento) + FALLBACKS\n",
    "\n",
    "# 3.1) Primeiro: por empresa (mais consistente)\n",
    "df[\"faturamento_empresa_brl\"] = df[\"faturamento_empresa_brl\"].fillna(\n",
    "    df.groupby(\"empresa\")[\"faturamento_empresa_brl\"].transform(\"median\")\n",
    ")\n",
    "\n",
    "# 3.2) Fallback: por (mercado_principal, tipo_cliente)\n",
    "df[\"faturamento_empresa_brl\"] = df[\"faturamento_empresa_brl\"].fillna(\n",
    "    df.groupby([\"mercado_principal\", \"tipo_cliente\"])[\"faturamento_empresa_brl\"].transform(\"median\")\n",
    ")\n",
    "\n",
    "# 3.3) Fallback: por mercado_principal\n",
    "df[\"faturamento_empresa_brl\"] = df[\"faturamento_empresa_brl\"].fillna(\n",
    "    df.groupby(\"mercado_principal\")[\"faturamento_empresa_brl\"].transform(\"median\")\n",
    ")\n",
    "\n",
    "# 3.4) Fallback final: mediana global\n",
    "df[\"faturamento_empresa_brl\"] = df[\"faturamento_empresa_brl\"].fillna(\n",
    "    df[\"faturamento_empresa_brl\"].median()\n",
    ")\n",
    "\n",
    "# 4) Categóricas: moda por grupo -> fallback \"Nao informado\"\n",
    "cat_cols = [\n",
    "    \"empresa\", \"produto\", \"tipo_cliente\",\n",
    "    \"mercado_principal\", \"certificacoes_principais\"\n",
    "]\n",
    "\n",
    "def fill_mode_by_group(data: pd.DataFrame, target: str, group_cols: list[str]) -> pd.DataFrame:\n",
    "    \"\"\"Preenche NaN em target com a moda dentro de cada grupo definido por group_cols.\"\"\"\n",
    "    mode_map = (\n",
    "        data.dropna(subset=[target])\n",
    "            .groupby(group_cols)[target]\n",
    "            .agg(lambda s: s.mode().iloc[0] if not s.mode().empty else np.nan)\n",
    "    )\n",
    "\n",
    "    idx = data[target].isna()\n",
    "    if idx.any():\n",
    "        keys = list(zip(*[data.loc[idx, g] for g in group_cols]))\n",
    "        data.loc[idx, target] = [mode_map.get(k, np.nan) for k in keys]\n",
    "    return data\n",
    "\n",
    "for c in cat_cols:\n",
    "    df = fill_mode_by_group(df, c, [\"empresa\", \"produto\"])\n",
    "    df = fill_mode_by_group(df, c, [\"empresa\"])\n",
    "    df = fill_mode_by_group(df, c, [\"produto\"])\n",
    "    df[c] = df[c].fillna(\"Nao informado\")\n",
    "\n",
    "# 5) Numéricas: imputação multivariada (MAR, cobre MCAR)\n",
    "num_cols = [\n",
    "    \"indice_concorrencia_1a5\",\n",
    "    \"indice_valor_agregado_1a5\",\n",
    "    \"margem_media_percentual\",\n",
    "    \"indice_complexidade_produtiva_1a5\",\n",
    "    \"indice_capex_1a5\",\n",
    "    \"indice_escalabilidade_1a5\",\n",
    "    \"indice_exigencia_regulatoria_1a5\",\n",
    "    \"indice_compatibilidade_refugo_1a5\",\n",
    "    \"indice_compatibilidade_operacao_fazenda_1a5\",\n",
    "]\n",
    "\n",
    "imp = IterativeImputer(\n",
    "    estimator=BayesianRidge(),\n",
    "    random_state=42,\n",
    "    max_iter=25,\n",
    "    sample_posterior=True,\n",
    "    skip_complete=True\n",
    ")\n",
    "\n",
    "df[num_cols] = imp.fit_transform(df[num_cols])\n",
    "\n",
    "# 6) Corrigir domínio dos índices (1..5 e 0.5 no valor agregado)\n",
    "\n",
    "int_indices = [\n",
    "    \"indice_concorrencia_1a5\",\n",
    "    \"indice_complexidade_produtiva_1a5\",\n",
    "    \"indice_capex_1a5\",\n",
    "    \"indice_escalabilidade_1a5\",\n",
    "    \"indice_exigencia_regulatoria_1a5\",\n",
    "    \"indice_compatibilidade_refugo_1a5\",\n",
    "    \"indice_compatibilidade_operacao_fazenda_1a5\",\n",
    "]\n",
    "df[int_indices] = df[int_indices].round().clip(1, 5)\n",
    "\n",
    "df[\"indice_valor_agregado_1a5\"] = (df[\"indice_valor_agregado_1a5\"] * 2).round() / 2\n",
    "df[\"indice_valor_agregado_1a5\"] = df[\"indice_valor_agregado_1a5\"].clip(1, 5)\n",
    "\n",
    "df[\"margem_media_percentual\"] = df[\"margem_media_percentual\"].clip(lower=0)\n",
    "\n",
    "\n",
    "\n",
    "total_missing_final = int(df.isna().sum().sum())\n",
    "print(\"Total de NaNs após tratamento:\", total_missing_final)\n",
    "\n",
    "imputed_report = pd.DataFrame({\n",
    "    \"missing_original\": missing_mask.sum(),\n",
    "    \"missing_final\": df.isna().sum()\n",
    "}).sort_values(\"missing_original\", ascending=False)\n",
    "\n",
    "print(imputed_report.head(20))\n",
    "\n",
    "# =========================\n",
    "# 8) Salvar base tratada\n",
    "# =========================\n",
    "df.to_csv(\"BASE_1_Manga_Produtos_TRATADA.csv\", index=False)\n",
    "print(\"Arquivo salvo: BASE_1_Manga_Produtos_TRATADA.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74685d43",
   "metadata": {},
   "source": [
    "Tratamento de dados faltantes: Inicialmente, foram criados indicadores binários de ausência (miss__coluna) para registrar onde existiam valores faltantes. Em seguida, o faturamento_empresa_brl foi imputado de forma condicional, priorizando a mediana por empresa e, quando necessário, aplicando uma cascata de fallback por grupos de negócio (mercado_principal e tipo_cliente) e por mercado_principal, com mediana global como último recurso. Para variáveis categóricas, os valores faltantes foram preenchidos pela moda por grupo (empresa+produto → empresa → produto), usando “Não informado” como fallback quando não havia informação suficiente. Já as variáveis numéricas (índices 1–5 e margem) foram imputadas via imputação multivariada (IterativeImputer/MICE-like), preservando as relações entre variáveis; ao final, os índices foram ajustados para respeitar seu domínio (1–5, com passos de 0,5 para valor agregado). Após o processo, a base ficou sem valores ausentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82a82c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algum índice fora de 1..5? False\n",
      "Valor agregado fora do domínio? False\n",
      "Valor agregado não múltiplo de 0.5? False\n",
      "Margem negativa? False\n",
      "Faturamento <= 0? False\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#1..5\n",
    "int_cols = [\n",
    "    \"indice_concorrencia_1a5\",\n",
    "    \"indice_complexidade_produtiva_1a5\",\n",
    "    \"indice_capex_1a5\",\n",
    "    \"indice_escalabilidade_1a5\",\n",
    "    \"indice_exigencia_regulatoria_1a5\",\n",
    "    \"indice_compatibilidade_refugo_1a5\",\n",
    "    \"indice_compatibilidade_operacao_fazenda_1a5\",\n",
    "]\n",
    "\n",
    "print(\"Algum índice fora de 1..5?\", ((df[int_cols] < 1) | (df[int_cols] > 5)).any().any())\n",
    "\n",
    "# valor agregado em 0.5\n",
    "va = df[\"indice_valor_agregado_1a5\"]\n",
    "print(\"Valor agregado fora do domínio?\", ((va < 1) | (va > 5)).any())\n",
    "print(\"Valor agregado não múltiplo de 0.5?\", ((va * 2) % 1 != 0).any())\n",
    "\n",
    "# margem\n",
    "print(\"Margem negativa?\", (df[\"margem_media_percentual\"] < 0).any())\n",
    "\n",
    "# faturamento\n",
    "print(\"Faturamento <= 0?\", (df[\"faturamento_empresa_brl\"] <= 0).any())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6113fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== margem_media_percentual ===\n",
      "Qtd imputada: 79\n",
      "Antes (observado) - média/mediana: 28.353275755706356 27.93\n",
      "Depois (imputado) - média/mediana: 28.766551160331158 29.73074189643633\n",
      "\n",
      "=== indice_valor_agregado_1a5 ===\n",
      "Qtd imputada: 98\n",
      "Antes (observado) - média/mediana: 2.9060549313358304 3.0\n",
      "Depois (imputado) - média/mediana: 2.8418367346938775 2.5\n",
      "\n",
      "=== indice_concorrencia_1a5 ===\n",
      "Qtd imputada: 84\n",
      "Antes (observado) - média/mediana: 2.9832920792079207 3.0\n",
      "Depois (imputado) - média/mediana: 3.0476190476190474 3.0\n",
      "\n",
      "=== indice_complexidade_produtiva_1a5 ===\n",
      "Qtd imputada: 78\n",
      "Antes (observado) - média/mediana: 3.0437731196054254 3.0\n",
      "Depois (imputado) - média/mediana: 2.9358974358974357 3.0\n",
      "\n",
      "=== indice_capex_1a5 ===\n",
      "Qtd imputada: 91\n",
      "Antes (observado) - média/mediana: 2.8228713486637664 3.0\n",
      "Depois (imputado) - média/mediana: 2.8351648351648353 3.0\n",
      "\n",
      "=== indice_escalabilidade_1a5 ===\n",
      "Qtd imputada: 90\n",
      "Antes (observado) - média/mediana: 3.0372670807453415 3.0\n",
      "Depois (imputado) - média/mediana: 3.1222222222222222 3.0\n",
      "\n",
      "=== indice_exigencia_regulatoria_1a5 ===\n",
      "Qtd imputada: 69\n",
      "Antes (observado) - média/mediana: 2.7664009809932555 3.0\n",
      "Depois (imputado) - média/mediana: 2.753623188405797 3.0\n",
      "\n",
      "=== indice_compatibilidade_refugo_1a5 ===\n",
      "Qtd imputada: 87\n",
      "Antes (observado) - média/mediana: 2.300061996280223 2.0\n",
      "Depois (imputado) - média/mediana: 2.206896551724138 2.0\n",
      "\n",
      "=== indice_compatibilidade_operacao_fazenda_1a5 ===\n",
      "Qtd imputada: 67\n",
      "Antes (observado) - média/mediana: 2.578689528475199 2.0\n",
      "Depois (imputado) - média/mediana: 2.6865671641791047 3.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_before = df_raw.copy() # base original\n",
    "df_after = df.copy() # base tratada\n",
    "cols_check = [\n",
    "    \"margem_media_percentual\",\n",
    "    \"indice_valor_agregado_1a5\",\n",
    "    *int_cols\n",
    "]\n",
    "\n",
    "for c in cols_check:\n",
    "    m = df_before[c].isna()\n",
    "    if m.sum() == 0:\n",
    "        continue\n",
    "    print(\"\\n===\", c, \"===\")\n",
    "    print(\"Qtd imputada:\", int(m.sum()))\n",
    "    print(\"Antes (observado) - média/mediana:\",\n",
    "          df_before.loc[~m, c].mean(), df_before.loc[~m, c].median())\n",
    "    print(\"Depois (imputado) - média/mediana:\",\n",
    "          df_after.loc[m, c].mean(), df_after.loc[m, c].median())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "419c2685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maiores mudanças de correlação (top 10):\n",
      "indice_complexidade_produtiva_1a5  indice_exigencia_regulatoria_1a5               0.015386\n",
      "                                   indice_compatibilidade_operacao_fazenda_1a5    0.013275\n",
      "margem_media_percentual            indice_capex_1a5                               0.011800\n",
      "indice_capex_1a5                   indice_compatibilidade_refugo_1a5              0.011304\n",
      "margem_media_percentual            indice_complexidade_produtiva_1a5              0.011175\n",
      "indice_escalabilidade_1a5          indice_compatibilidade_refugo_1a5              0.010636\n",
      "faturamento_empresa_brl            margem_media_percentual                        0.010543\n",
      "indice_complexidade_produtiva_1a5  indice_capex_1a5                               0.010107\n",
      "margem_media_percentual            indice_exigencia_regulatoria_1a5               0.009816\n",
      "indice_complexidade_produtiva_1a5  indice_escalabilidade_1a5                      0.008906\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "num_cols = [\n",
    "    \"faturamento_empresa_brl\",\n",
    "    \"margem_media_percentual\",\n",
    "    \"indice_valor_agregado_1a5\",\n",
    "    *int_cols\n",
    "]\n",
    "\n",
    "corr_before = df_raw[num_cols].corr(numeric_only=True)\n",
    "corr_after  = df_after[num_cols].corr(numeric_only=True)\n",
    "\n",
    "diff = (corr_after - corr_before).abs()\n",
    "\n",
    "print(\"Maiores mudanças de correlação (top 10):\")\n",
    "pairs = diff.where(np.triu(np.ones(diff.shape), k=1).astype(bool)).stack().sort_values(ascending=False)\n",
    "print(pairs.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a32dfca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " margem_media_percentual\n",
      "STD observado: 10.709330860174099\n",
      "STD imputado : 11.378865202474529\n",
      "\n",
      " indice_valor_agregado_1a5\n",
      "STD observado: 0.8048538211581536\n",
      "STD imputado : 0.9041625925065672\n",
      "\n",
      " indice_concorrencia_1a5\n",
      "STD observado: 1.1437131658150064\n",
      "STD imputado : 1.063125216811627\n",
      "\n",
      " indice_complexidade_produtiva_1a5\n",
      "STD observado: 1.1206909685879753\n",
      "STD imputado : 1.0486818391359698\n",
      "\n",
      " indice_capex_1a5\n",
      "STD observado: 1.2279189850359327\n",
      "STD imputado : 1.195024279286002\n",
      "\n",
      " indice_escalabilidade_1a5\n",
      "STD observado: 1.1391021660318037\n",
      "STD imputado : 1.0791983893360702\n",
      "\n",
      " indice_exigencia_regulatoria_1a5\n",
      "STD observado: 1.1863225576944674\n",
      "STD imputado : 1.1167942185170971\n",
      "\n",
      " indice_compatibilidade_refugo_1a5\n",
      "STD observado: 1.2564399847824137\n",
      "STD imputado : 1.0245581127409613\n",
      "\n",
      " indice_compatibilidade_operacao_fazenda_1a5\n",
      "STD observado: 1.2631995236359355\n",
      "STD imputado : 1.245707237650876\n"
     ]
    }
   ],
   "source": [
    "cols = [\n",
    "    \"margem_media_percentual\",\n",
    "    \"indice_valor_agregado_1a5\",\n",
    "    \"indice_concorrencia_1a5\",\n",
    "    \"indice_complexidade_produtiva_1a5\",\n",
    "    \"indice_capex_1a5\",\n",
    "    \"indice_escalabilidade_1a5\",\n",
    "    \"indice_exigencia_regulatoria_1a5\",\n",
    "    \"indice_compatibilidade_refugo_1a5\",\n",
    "    \"indice_compatibilidade_operacao_fazenda_1a5\",\n",
    "]\n",
    "\n",
    "for c in cols:\n",
    "    m = df_raw[c].isna()\n",
    "    if m.sum() == 0:\n",
    "        continue\n",
    "    print(\"\\n\", c)\n",
    "    print(\"STD observado:\", df_raw.loc[~m, c].std())\n",
    "    print(\"STD imputado :\", df.loc[m, c].std())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.venv analise)",
   "language": "python",
   "name": "analise-kshs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
