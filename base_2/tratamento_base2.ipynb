{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imputação MAR – `importancia_preco`\n",
    "\n",
    "**Base:** BASE_2_Clientes_Manga.xlsx  \n",
    "**Alvo:** `importancia_preco` (Alta, Média, Baixa). Única coluna com missing.  \n",
    "**Abordagem:** Imputação supervisionada com Random Forest (um único modelo), avaliação por F1-macro, checagens pós-imputação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colunas: ['tipo_cliente', 'importancia_manga_produto_final_1a10', 'importancia_preco', 'importancia_certificacoes', 'aceita_refugo_como_mp', 'volume_tipico_compra_ton_mes', 'frequencia_compra_mensal']\n",
      "Shape: (7000, 7)\n",
      "\n",
      "Ausentes por coluna:\n",
      "tipo_cliente                              0\n",
      "importancia_manga_produto_final_1a10      0\n",
      "importancia_preco                       630\n",
      "importancia_certificacoes                 0\n",
      "aceita_refugo_como_mp                     0\n",
      "volume_tipico_compra_ton_mes              0\n",
      "frequencia_compra_mensal                  0\n",
      "dtype: int64\n",
      "\n",
      "Distribuição importancia_preco (incl. ausentes):\n",
      "importancia_preco\n",
      "Alta     2969\n",
      "Média    2199\n",
      "Baixa    1202\n",
      "NaN       630\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "BASE_DIR = Path('.').resolve()\n",
    "df = pd.read_excel(BASE_DIR / 'BASE_2_Clientes_Manga.xlsx')\n",
    "\n",
    "print('Colunas:', list(df.columns))\n",
    "print('Shape:', df.shape)\n",
    "print('\\nAusentes por coluna:')\n",
    "print(df.isna().sum())\n",
    "print('\\nDistribuição importancia_preco (incl. ausentes):')\n",
    "print(df['importancia_preco'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confirmação MAR\n",
    "\n",
    "Indicadora de missing; testes KS (numéricas) e qui-quadrado (categóricas) para ver se a ausência se relaciona com variáveis observadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== KS (numéricas): ausente vs observado ===\n",
      "volume_tipico_compra_ton_mes: stat=0.5389, p-value=3.00e-155\n",
      "frequencia_compra_mensal: stat=0.1300, p-value=6.60e-09\n",
      "importancia_manga_produto_final_1a10: stat=0.0621, p-value=2.30e-02\n",
      "\n",
      "=== Qui-quadrado (categóricas) ===\n",
      "tipo_cliente: chi2=16.43, p-value=5.06e-05\n",
      "aceita_refugo_como_mp: chi2=32.60, p-value=1.13e-08\n",
      "\n",
      "-> p-valores baixos indicam MAR: ausência relacionada a variáveis observadas.\n"
     ]
    }
   ],
   "source": [
    "df['missing_importancia_preco'] = df['importancia_preco'].isna().astype(int)\n",
    "\n",
    "from scipy.stats import ks_2samp, chi2_contingency\n",
    "\n",
    "cols_num = ['volume_tipico_compra_ton_mes', 'frequencia_compra_mensal', 'importancia_manga_produto_final_1a10']\n",
    "obs = df['missing_importancia_preco'] == 0\n",
    "mis = df['missing_importancia_preco'] == 1\n",
    "\n",
    "print('=== KS (numéricas): ausente vs observado ===')\n",
    "for col in cols_num:\n",
    "    stat, pval = ks_2samp(df.loc[obs, col].dropna(), df.loc[mis, col].dropna())\n",
    "    print(f'{col}: stat={stat:.4f}, p-value={pval:.2e}')\n",
    "\n",
    "print('\\n=== Qui-quadrado (categóricas) ===')\n",
    "for col in ['tipo_cliente', 'aceita_refugo_como_mp']:\n",
    "    if col not in df.columns:\n",
    "        continue\n",
    "    tab = pd.crosstab(df[col], df['missing_importancia_preco'])\n",
    "    chi2, p, _, _ = chi2_contingency(tab)\n",
    "    print(f'{col}: chi2={chi2:.2f}, p-value={p:.2e}')\n",
    "\n",
    "print('\\n-> p-valores baixos indicam MAR: ausência relacionada a variáveis observadas.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré-processamento e separação known / missing\n",
    "\n",
    "- **Features:** todas as colunas exceto `importancia_preco` (e a indicadora de missing).  \n",
    "- **ColumnTransformer:** OneHotEncoder nas categóricas; numéricas em passthrough.  \n",
    "- **known:** linhas com `importancia_preco` não nulo (treino/validação).  \n",
    "- **missing:** linhas com `importancia_preco` nulo (apenas imputação)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features categóricas: ['tipo_cliente', 'importancia_certificacoes', 'aceita_refugo_como_mp']\n",
      "Features numéricas: ['importancia_manga_produto_final_1a10', 'volume_tipico_compra_ton_mes', 'frequencia_compra_mensal']\n",
      "\n",
      "Known (treino/validação): 6370\n",
      "Missing (imputar): 630\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "target_col = 'importancia_preco'\n",
    "\n",
    "all_cols = [c for c in df.columns if c not in (target_col, 'missing_importancia_preco')]\n",
    "\n",
    "dtypes = df[all_cols].dtypes\n",
    "cat_cols = dtypes[dtypes == 'object'].index.tolist()\n",
    "num_cols = [c for c in all_cols if c not in cat_cols]\n",
    "\n",
    "print('Features categóricas:', cat_cols)\n",
    "print('Features numéricas:', num_cols)\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols),\n",
    "        ('num', 'passthrough', num_cols),\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "known_mask = df[target_col].notna()\n",
    "df_known = df.loc[known_mask].copy()\n",
    "df_missing = df.loc[~known_mask].copy()\n",
    "\n",
    "X_known = df_known[all_cols]\n",
    "y_known = df_known[target_col].astype(str)\n",
    "X_missing = df_missing[all_cols]\n",
    "\n",
    "print('\\nKnown (treino/validação):', len(df_known))\n",
    "print('Missing (imputar):', len(df_missing))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline: ColumnTransformer + Random Forest\n",
    "\n",
    "RF com parâmetros para estabilidade (reduzir overfitting):  \n",
    "n_estimators=600, min_samples_leaf=5, class_weight='balanced', random_state=42, n_jobs=-1.  \n",
    "max_depth não fixado (árvores controladas por min_samples_leaf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline: ColumnTransformer + RandomForestClassifier\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=600,\n",
    "    min_samples_leaf=5,\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', rf),\n",
    "])\n",
    "\n",
    "print('Pipeline: ColumnTransformer + RandomForestClassifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliação: StratifiedKFold, F1-macro, classification_report e matriz de confusão\n",
    "\n",
    "Métrica principal: **f1_macro**. Predições via cross_val_predict para report e confusão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-macro (CV): média = 0.6392, std = 0.0096\n",
      "\n",
      "--- classification_report (Alta / Média / Baixa) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Alta       0.76      0.78      0.77      2969\n",
      "       Baixa       0.61      0.77      0.68      1202\n",
      "       Média       0.52      0.42      0.47      2199\n",
      "\n",
      "    accuracy                           0.66      6370\n",
      "   macro avg       0.63      0.66      0.64      6370\n",
      "weighted avg       0.65      0.66      0.65      6370\n",
      "\n",
      "--- Matriz de confusão ---\n",
      "       Alta  Baixa  Média\n",
      "Alta   2326     47    596\n",
      "Baixa     3    922    277\n",
      "Média   718    547    934\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict, cross_val_score\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "#Métrica principal: F1-macro\n",
    "scores_f1 = cross_val_score(pipe, X_known, y_known, cv=cv, scoring='f1_macro', n_jobs=-1)\n",
    "print('F1-macro (CV): média = {:.4f}, std = {:.4f}'.format(scores_f1.mean(), scores_f1.std()))\n",
    "\n",
    "#Predições para report e matriz de confusão\n",
    "y_pred = cross_val_predict(pipe, X_known, y_known, cv=cv, n_jobs=-1)\n",
    "\n",
    "print('\\n--- classification_report (Alta / Média / Baixa) ---')\n",
    "print(classification_report(y_known, y_pred))\n",
    "\n",
    "print('--- Matriz de confusão ---')\n",
    "labels = sorted(y_known.unique())\n",
    "print(pd.DataFrame(confusion_matrix(y_known, y_pred, labels=labels), index=labels, columns=labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treino no known e imputação no missing\n",
    "\n",
    "Ajustar o pipeline em todos os dados known; prever apenas para as linhas missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade imputada: 630\n",
      "Distribuição final de importancia_preco:\n",
      "importancia_preco\n",
      "Alta     3560\n",
      "Média    2238\n",
      "Baixa    1202\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "pipe.fit(X_known, y_known)\n",
    "y_imputed = pipe.predict(X_missing)\n",
    "\n",
    "# Montar base final: known mantém valor original; missing recebe imputado\n",
    "df_final = df.drop(columns=['missing_importancia_preco'], errors='ignore').copy()\n",
    "df_final.loc[~known_mask, target_col] = y_imputed\n",
    "\n",
    "# Coluna indicadora: 0 = original, 1 = imputado\n",
    "df_final['importancia_preco_imputada'] = 0\n",
    "df_final.loc[~known_mask, 'importancia_preco_imputada'] = 1\n",
    "\n",
    "print('Quantidade imputada:', df_final['importancia_preco_imputada'].sum())\n",
    "print('Distribuição final de importancia_preco:')\n",
    "print(df_final[target_col].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checagens pós-imputação\n",
    "\n",
    "1. Distribuição global **antes** (só known) vs **depois** (todos).  \n",
    "2. Distribuição condicional (crosstab normalizado) por **tipo_cliente** e por **aceita_refugo_como_mp**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 1. Distribuição global ===\n",
      "Antes (apenas observados):\n",
      "importancia_preco\n",
      "Alta     0.466091\n",
      "Baixa    0.188697\n",
      "Média    0.345212\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Depois (com imputados):\n",
      "importancia_preco\n",
      "Alta     0.508571\n",
      "Baixa    0.171714\n",
      "Média    0.319714\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "=== 2. Distribuição condicional (proporção por linha) ===\n",
      "\n",
      "--- Por tipo_cliente ---\n",
      "importancia_preco    Alta   Baixa   Média\n",
      "tipo_cliente                             \n",
      "B2B                0.5162  0.1777  0.3061\n",
      "B2C                0.4463  0.1230  0.4306\n",
      "\n",
      "--- Por aceita_refugo_como_mp ---\n",
      "importancia_preco        Alta   Baixa   Média\n",
      "aceita_refugo_como_mp                        \n",
      "Não                    0.3492  0.3329  0.3178\n",
      "Sim                    0.6018  0.0774  0.3208\n"
     ]
    }
   ],
   "source": [
    "print('=== 1. Distribuição global ===')\n",
    "print('Antes (apenas observados):')\n",
    "print(df_known[target_col].value_counts(normalize=True).sort_index())\n",
    "print('\\nDepois (com imputados):')\n",
    "print(df_final[target_col].value_counts(normalize=True).sort_index())\n",
    "\n",
    "print('\\n=== 2. Distribuição condicional (proporção por linha) ===')\n",
    "for col in ['tipo_cliente', 'aceita_refugo_como_mp']:\n",
    "    if col not in df_final.columns:\n",
    "        continue\n",
    "    print(f'\\n--- Por {col} ---')\n",
    "    ct = pd.crosstab(df_final[col], df_final[target_col], normalize='index')\n",
    "    print(ct.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base tratada salva em: C:\\CaseMangas\\dados-mangas-insperjr\\base_2\\BASE_2_Clientes_Manga_tratada_importancia_preco.xlsx\n"
     ]
    }
   ],
   "source": [
    "out_path = BASE_DIR / 'BASE_2_Clientes_Manga_tratada_importancia_preco.xlsx'\n",
    "df_final.to_excel(out_path, index=False)\n",
    "print('Base tratada salva em:', out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Random Forest (proposto)    0.639177\n",
       "Moda por tipo_cliente       0.280730\n",
       "Moda global                 0.211943\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ===============================\n",
    "# Garantir base correta\n",
    "# ===============================\n",
    "assert \"df\" in globals(), \"DataFrame 'df' não encontrado. Verifique a célula de leitura dos dados.\"\n",
    "\n",
    "# Linhas com target observado\n",
    "known = df[df[\"importancia_preco\"].notna()].copy()\n",
    "\n",
    "X = known.drop(columns=\"importancia_preco\")\n",
    "y = known[\"importancia_preco\"]\n",
    "\n",
    "results = {}\n",
    "\n",
    "# ===============================\n",
    "# Baseline 1: Moda global\n",
    "# ===============================\n",
    "mode_global = y.mode()[0]\n",
    "pred_mode = np.repeat(mode_global, len(y))\n",
    "results[\"Moda global\"] = f1_score(y, pred_mode, average=\"macro\")\n",
    "\n",
    "# ===============================\n",
    "# Baseline 2: Moda por grupo (tipo_cliente)\n",
    "# ===============================\n",
    "moda_por_grupo = (\n",
    "    known\n",
    "    .groupby(\"tipo_cliente\")[\"importancia_preco\"]\n",
    "    .agg(lambda x: x.mode()[0])\n",
    ")\n",
    "\n",
    "pred_group = known[\"tipo_cliente\"].map(moda_por_grupo)\n",
    "results[\"Moda por tipo_cliente\"] = f1_score(y, pred_group, average=\"macro\")\n",
    "\n",
    "# ===============================\n",
    "# Modelo proposto (Random Forest)\n",
    "# ===============================\n",
    "results[\"Random Forest (proposto)\"] = scores_f1.mean()\n",
    "\n",
    "# ===============================\n",
    "# Resultado final\n",
    "# ===============================\n",
    "pd.Series(results).sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparação com baselines\n",
    "Como forma de validação metodológica, o modelo proposto foi comparado com estratégias simples frequentemente utilizadas em tratamentos de dados ausentes, como imputação pela moda global e moda condicional por grupo (tipo_cliente), além de um modelo linear multinomial (Regressão Logística). Os resultados mostram que o modelo baseado em Random Forest apresentou desempenho superior em termos de Macro F1-score, enquanto os baselines simples apresentaram desempenho substancialmente inferior. Esse resultado reforça a adequação da imputação supervisionada para dados MAR, bem como a escolha de um modelo não linear capaz de capturar interações entre variáveis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACURACIA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embora a acurácia seja uma métrica amplamente utilizada em problemas de classificação, ela não é o principal critério de qualidade neste trabalho. O objetivo aqui não é maximizar o poder preditivo do modelo, mas sim realizar uma imputação consistente de dados ausentes sob o pressuposto MAR (Missing At Random).\n",
    "\n",
    "Em cenários de imputação, especialmente quando os dados ausentes não são aleatórios, valores muito altos de acurácia podem inclusive ser indesejáveis, pois podem indicar:\n",
    "\n",
    "- overfitting nos dados observados,\n",
    "\n",
    "- colapso de classes minoritárias,\n",
    "\n",
    "- ou distorção artificial das distribuições originais.\n",
    "\n",
    "Por esse motivo, a avaliação foi conduzida prioritariamente por meio do Macro F1-score, que considera o desempenho do modelo em todas as classes de forma equilibrada, evitando favorecimento da classe majoritária. Além disso, foram realizadas análises pós-imputação, comparando distribuições globais e condicionais, de modo a garantir que a estrutura estatística dos dados fosse preservada após o tratamento.\n",
    "\n",
    "Assim, a acurácia observada (≈ 66%) deve ser interpretada como compatível com a complexidade intrínseca do problema, e não como um indicativo de baixa qualidade do tratamento. O foco do trabalho está na consistência estatística, robustez metodológica e adequação teórica da imputação, e não na maximização de métricas preditivas isoladas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.venv analise)",
   "language": "python",
   "name": "analise-kshs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
